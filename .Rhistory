across(where(is.numeric), ~mean(.x, na.rm=T))) %>%
select(-c(row_num, Participant.x, Participant.y, Study, VerbalIQ, NonVerbalIQ, TotalIQ))
sum_dat %>%
summarise(across(.fns = ~sum(is.na(.x))))
# Create dataset with one row (JESUS!) per customer
sum_dat <- danish_dat %>%
group_by(real_ID) %>%
summarise(Diagnosis = first(Diagnosis),
across(where(is.numeric), ~mean(.x, na.rm=T))) %>%
select(-c(row_num, Participant.x, Participant.y, Study, VerbalIQ, NonVerbalIQ, TotalIQ)) %>%
replace_na(list(SANS = 0, SAPS = 0))
sum_dat %>%
summarise(across(.fns = ~sum(is.na(.x))))
# Defining recipe + preprocessing
skizo_recipe <- recipe(Diagnosis ~ ., data = sum_dat) %>%
step_normalize(all_numeric()) %>%
step_knnimpute(age)
# Defining model
lr_mod <-
logistic_reg(penalty = tune(),
mixture = 1) %>% # LASSO
set_engine("glmnet") %>%
set_mode("classification")
# Create the workflow
lr_workflow <- workflow() %>%
add_recipe(skizo_recipe) %>%
add_model(lr_mod)
# Tune model #
# Define grid
lr_reg_grid <- tibble(penalty = 10^seq(-4, -1, length.out = 30))
# Actually tuning!
lr_tune_results <- lr_workflow %>%
tune_grid(resamples = skizo_cv,
grid = lr_reg_grid,
metrics = metric_set(accuracy, roc_auc))
# Defining recipe + preprocessing
skizo_recipe <- recipe(Diagnosis ~ ., data = sum_dat) %>%
step_normalize(all_numeric()) %>%
step_knnimpute(Age)
# Defining model
lr_mod <-
logistic_reg(penalty = tune(),
mixture = 1) %>% # LASSO
set_engine("glmnet") %>%
set_mode("classification")
# Create the workflow
lr_workflow <- workflow() %>%
add_recipe(skizo_recipe) %>%
add_model(lr_mod)
# Tune model #
# Define grid
lr_reg_grid <- tibble(penalty = 10^seq(-4, -1, length.out = 30))
# Actually tuning!
lr_tune_results <- lr_workflow %>%
tune_grid(resamples = skizo_cv,
grid = lr_reg_grid,
metrics = metric_set(accuracy, roc_auc))
# Actually tuning!
lr_tune_results <- lr_workflow %>%
tune_grid(resamples = skizo_cv,
grid = lr_reg_grid,
metrics = metric_set(accuracy, roc_auc))
sum_dat %>%
summarise(across(.fns = ~sum(is.na(.x))))
# Create dataset with one row (JESUS!) per customer
sum_dat <- danish_dat %>%
group_by(real_ID) %>%
summarise(Diagnosis = first(Diagnosis),
across(where(is.numeric), ~mean(.x, na.rm=T))) %>%
select(-c(row_num, Participant.x, Participant.y, Study, VerbalIQ, NonVerbalIQ, TotalIQ, Age)) %>%
replace_na(list(SANS = 0, SAPS = 0))
sum_dat %>%
summarise(across(.fns = ~sum(is.na(.x))))
# Defining recipe + preprocessing
skizo_recipe <- recipe(Diagnosis ~ ., data = sum_dat) %>%
step_normalize(all_numeric())
# Defining model
lr_mod <-
logistic_reg(penalty = tune(),
mixture = 1) %>% # LASSO
set_engine("glmnet") %>%
set_mode("classification")
# Create the workflow
lr_workflow <- workflow() %>%
add_recipe(skizo_recipe) %>%
add_model(lr_mod)
# Tune model #
# Define grid
lr_reg_grid <- tibble(penalty = 10^seq(-4, -1, length.out = 30))
# Actually tuning!
lr_tune_results <- lr_workflow %>%
tune_grid(resamples = skizo_cv,
grid = lr_reg_grid,
metrics = metric_set(accuracy, roc_auc))
# Create dataset with one row (JESUS!) per customer
sum_dat <- danish_dat %>%
group_by(real_ID) %>%
summarise(Diagnosis = first(Diagnosis),
across(where(is.numeric), ~mean(.x, na.rm=T))) %>%
select(-c(row_num, Participant.x, Participant.y, Study, VerbalIQ, NonVerbalIQ, TotalIQ, Age)) %>%
replace_na(list(SANS = 0, SAPS = 0))
sum_dat %>%
summarise(across(.fns = ~sum(is.na(.x))))
split_personality <- initial_split(sum_dat, strata = Diagnosis)
skizo_train <- training(split_personality)
skizo_test <- testing(split_personality)
skizo_cv <- vfold_cv(skizo_train, repeats=1, strata = Diagnosis)
# Defining recipe + preprocessing
skizo_recipe <- recipe(Diagnosis ~ ., data = sum_dat) %>%
step_normalize(all_numeric())
# Defining model
lr_mod <-
logistic_reg(penalty = tune(),
mixture = 1) %>% # LASSO
set_engine("glmnet") %>%
set_mode("classification")
# Create the workflow
lr_workflow <- workflow() %>%
add_recipe(skizo_recipe) %>%
add_model(lr_mod)
# Tune model #
# Define grid
lr_reg_grid <- tibble(penalty = 10^seq(-4, -1, length.out = 30))
# Actually tuning!
lr_tune_results <- lr_workflow %>%
tune_grid(resamples = skizo_cv,
grid = lr_reg_grid,
metrics = metric_set(accuracy, roc_auc))
lr_tune_results$.notes
sum_dat %>%
summarise(across(.fns = ~sum(is.na(.x)))) %>%
select(across(.fns = ~any(is.na(.x))))
sum_dat %>%
summarise(across(.fns = ~sum(is.na(.x)))) %>%
dplyr::select(across(.fns = ~any(is.na(.x))))
sum_dat %>%
summarise(across(.fns = ~sum(is.na(.x))))
# Create dataset with one row (JESUS!) per customer
sum_dat <- danish_dat %>%
group_by(real_ID) %>%
summarise(Diagnosis = first(Diagnosis),
across(where(is.numeric), ~mean(.x, na.rm=T))) %>%
select(-c(row_num, Participant.x, Participant.y, Study, VerbalIQ, NonVerbalIQ, TotalIQ, Age)) %>%
replace_na(list(SANS = 0, SAPS = 0))
sum_dat %>%
summarise(across(.fns = ~sum(is.na(.x))))
split_personality <- initial_split(sum_dat, strata = Diagnosis)
skizo_train <- training(split_personality)
skizo_test <- testing(split_personality)
skizo_cv <- vfold_cv(skizo_train, repeats=1, strata = Diagnosis)
# Defining recipe + preprocessing
skizo_recipe <- recipe(Diagnosis ~ ., data = sum_dat) %>%
step_normalize(all_numeric())
# Defining model
lr_mod <-
logistic_reg(penalty = tune(),
mixture = 1) %>% # LASSO
set_engine("glmnet") %>%
set_mode("classification")
# Create the workflow
lr_workflow <- workflow() %>%
add_recipe(skizo_recipe) %>%
add_model(lr_mod)
# Tune model #
# Define grid
lr_reg_grid <- tibble(penalty = 10^seq(-4, -1, length.out = 30))
# Actually tuning!
lr_tune_results <- lr_workflow %>%
tune_grid(resamples = skizo_cv,
grid = lr_reg_grid,
metrics = metric_set(accuracy, roc_auc))
lr_tune_results$.notes
# Tune model #
# Define grid
lr_reg_grid <- tibble(penalty = 10^seq(1, -10, length.out = 30))
# Actually tuning!
lr_tune_results <- lr_workflow %>%
tune_grid(resamples = skizo_cv,
grid = lr_reg_grid,
metrics = metric_set(accuracy, roc_auc))
# Tune model #
# Define grid
lr_reg_grid <- tibble(penalty = 10^seq(0.1, 10, length.out = 30))
# Actually tuning!
lr_tune_results <- lr_workflow %>%
tune_grid(resamples = skizo_cv,
grid = lr_reg_grid,
metrics = metric_set(accuracy, roc_auc))
# Tune model #
# Define grid
lr_reg_grid <- tibble(penalty = 10^seq(-1, 1, length.out = 1))
# Actually tuning!
lr_tune_results <- lr_workflow %>%
tune_grid(resamples = skizo_cv,
grid = lr_reg_grid,
metrics = metric_set(accuracy, roc_auc))
skizo_cv <- vfold_cv(skizo_train, v=2, repeats=1, strata = Diagnosis)
# Defining recipe + preprocessing
skizo_recipe <- recipe(Diagnosis ~ ., data = sum_dat) %>%
step_normalize(all_numeric())
# Defining model
lr_mod <-
logistic_reg(penalty = tune(),
mixture = 1) %>% # LASSO
set_engine("glmnet") %>%
set_mode("classification")
# Create the workflow
lr_workflow <- workflow() %>%
add_recipe(skizo_recipe) %>%
add_model(lr_mod)
# Tune model #
# Define grid
lr_reg_grid <- tibble(penalty = 10^seq(-1, 1, length.out = 1))
# Actually tuning!
lr_tune_results <- lr_workflow %>%
tune_grid(resamples = skizo_cv,
grid = lr_reg_grid,
metrics = metric_set(accuracy, roc_auc))
lr_tune_results$.notes
# Defining model
lr_mod <-
logistic_reg(penalty = 1,
mixture = 1) %>% # LASSO
set_engine("glmnet") %>%
set_mode("classification")
# Actually tuning!
lr_tune_results <- lr_workflow %>%
tune_grid(resamples = skizo_cv,
grid = lr_reg_grid,
metrics = metric_set(accuracy, roc_auc))
# Actually tuning!
lr_tune_results <- lr_workflow %>%
tune_grid(resamples = skizo_cv,
metrics = metric_set(accuracy, roc_auc))
lr_tune_results$.notes
knitr::opts_chunk$set(echo = TRUE)
library(cvms)
library(groupdata2)
rm(list=ls())
gc()
library(tidymodels)
library(tidyverse)
library(lmerTest)
library(broom.mixed)
library(e1071)
library(caret)
raw_dat <- read_csv("https://raw.githubusercontent.com/EyesOfKasparov/methods3_A3/master/finalish_data.csv")
logit2prob <- function(x) {
# https://www.wolframalpha.com/input/?i=log%28p%2F%281-p%29%29+%3D+x+isolate+p
exp(x) / (1+exp(x))
}
predict_to_tibble <- function(model) {
predict(model, re.form=NA, type="response") %>%
as_tibble() %>%
mutate(row_num = row_number(),
pred = if_else(value > 0.5, "Schizophrenia", "Control")) %>%
select(row_num, pred)
}
danish_dat <- raw_dat %>%
filter(Language == "Danish") %>%
rename(pitch_variability = freq_iqr) %>%
mutate(Diagnosis = as_factor(Diagnosis),
row_num = row_number())
simple_model <- glmer(Diagnosis ~ pitch_variability + (1|real_ID) + (1|Study), data = danish_dat, family = "binomial", control=lme4::glmerControl(optimizer="bobyqa"))
simple_fixed <- glm(Diagnosis ~ pitch_variability, danish_dat, family = "binomial")
summary(simple_model)
result <- predict_to_tibble(simple_fixed) %>%
left_join(danish_dat) %>%
select(pred, Diagnosis)
result
?confusionMatrix()
confusionMatrix(result$pred, result$Diagnosis)
result <- predict_to_tibble(simple_fixed) %>%
left_join(danish_dat) %>%
select(pred, Diagnosis) %>%
mutate(across(.fns=as_factor()))
result <- predict_to_tibble(simple_fixed) %>%
left_join(danish_dat) %>%
select(pred, Diagnosis) %>%
mutate(across(everything(), as_factor()))
result <- predict_to_tibble(simple_fixed) %>%
left_join(danish_dat) %>%
select(pred, Diagnosis)
result
result <- predict_to_tibble(simple_fixed) %>%
left_join(danish_dat) %>%
select(pred, Diagnosis) %>%
mutate(across(everything(), as.factor()))
result <- predict_to_tibble(simple_fixed) %>%
left_join(danish_dat) %>%
select(pred, Diagnosis) %>%
mutate(pred = as_factor(pred))
confusionMatrix(result$pred, result$Diagnosis)
install.packages("pROC")
install.packages("pROC")
knitr::opts_chunk$set(echo = TRUE)
library(plotR)
rm(list=ls())
gc()
library(tidymodels)
library(tidyverse)
library(lmerTest)
library(broom.mixed)
library(e1071)
library(caret)
#install.packages("pROC")
library(pROC)
raw_dat <- read_csv("https://raw.githubusercontent.com/EyesOfKasparov/methods3_A3/master/finalish_data.csv")
logit2prob <- function(x) {
# https://www.wolframalpha.com/input/?i=log%28p%2F%281-p%29%29+%3D+x+isolate+p
exp(x) / (1+exp(x))
}
predict_to_tibble <- function(model) {
predict(model, re.form=NA, type="response") %>%
as_tibble() %>%
mutate(row_num = row_number(),
pred = if_else(value > 0.5, "Schizophrenia", "Control")) %>%
select(row_num, pred)
}
danish_dat <- raw_dat %>%
filter(Language == "Danish") %>%
rename(pitch_variability = freq_iqr) %>%
mutate(Diagnosis = as_factor(Diagnosis),
row_num = row_number())
?plot.roc()
plot.roc(result$pred, result$Diagnosis)
simple_model <- glmer(Diagnosis ~ pitch_variability + (1|real_ID) + (1|Study), data = danish_dat, family = "binomial", control=lme4::glmerControl(optimizer="bobyqa"))
simple_fixed <- glm(Diagnosis ~ pitch_variability, danish_dat, family = "binomial")
summary(simple_model)
result <- predict_to_tibble(simple_fixed) %>%
left_join(danish_dat) %>%
select(pred, Diagnosis) %>%
mutate(pred = as_factor(pred))
confusionMatrix(result$pred, result$Diagnosis)
plot.roc(result$pred, result$Diagnosis)
plot.roc(result$pred, result$Diagnosis)
levels(result$pred)
result <- predict_to_tibble(simple_fixed) %>%
left_join(danish_dat) %>%
select(pred, Diagnosis)
result$pred
?factor()
result <- predict_to_tibble(simple_fixed) %>%
left_join(danish_dat) %>%
select(pred, Diagnosis) %>%
mutate(pred = factor(pred, levels = levels(Diagnosis)))
plot.roc(result$pred, result$Diagnosis)
Metrics::auc(result$Diagnosis, result$pred)
result <- predict_to_tibble(simple_fixed) %>%
left_join(danish_dat) %>%
select(pred, Diagnosis) %>%
mutate(pred = factor(pred, levels = levels(Diagnosis)))
result <- predict_to_tibble(simple_fixed) %>%
left_join(danish_dat) %>%
select(pred, Diagnosis)
Metrics::auc(result$Diagnosis, result$pred)
result
Metrics::auc(result$Diagnosis, result$pred)
result <- predict_to_tibble(simple_fixed) %>%
left_join(danish_dat) %>%
select(pred, Diagnosis) %>%
mutate(across(everything(), ~if_else(.x == "Diagnosis", 0, 1)))
Metrics::auc(result$Diagnosis, result$pred)
confusionMatrix(result$pred, result$Diagnosis)
result <- predict_to_tibble(simple_fixed) %>%
left_join(danish_dat) %>%
select(pred, Diagnosis)
confusionMatrix(result$pred, result$Diagnosis)
result <- predict_to_tibble(simple_fixed) %>%
left_join(danish_dat) %>%
select(pred, Diagnosis) %>%
mutate(pred = factor(pred, levels = levels(Diagnosis)))
confusionMatrix(result$pred, result$Diagnosis)
Metrics::auc(result$Diagnosis, result$pred)
result$pred
Metrics::auc(as.numeric(result$Diagnosis), as.numeric(result$pred))
Metrics::auc(as.numeric(result$Diagnosis), as.numeric(result$pred))
my_auc <- function(obs, pred) {
Metrics::auc(as.numeric(Diagnosis), as.numeric(pred))
}
logit2prob <- function(x) {
# https://www.wolframalpha.com/input/?i=log%28p%2F%281-p%29%29+%3D+x+isolate+p
exp(x) / (1+exp(x))
}
predict_to_tibble <- function(model) {
predict(model, re.form=NA, type="response") %>%
as_tibble() %>%
mutate(row_num = row_number(),
pred = if_else(value > 0.5, "Schizophrenia", "Control")) %>%
select(row_num, pred)
}
my_auc <- function(obs, pred) {
Metrics::auc(as.numeric(Diagnosis), as.numeric(pred))
}
my_auc(result$Diagnosis, result$pred)
my_auc <- function(obs, pred) {
Metrics::auc(as.numeric(obs), as.numeric(pred))
}
my_auc(result$Diagnosis, result$pred)
confusionMatrix(result$pred, result$Diagnosis)
danish_dat
fold_model_data <- danish_dat %>%
mutate(real_ID = as_factor(real_ID)) %>%
fold(
data = ., k = 10,
cat_col = 'diagnosis',
id_col = 'real_ID',
num_fold_cols = 3,
handle_existing_fold_cols = "keep"
)
library(cvms)
library(groupdata2)
fold_model_data <- danish_dat %>%
mutate(real_ID = as_factor(real_ID)) %>%
fold(
data = ., k = 10,
cat_col = 'diagnosis',
id_col = 'real_ID',
num_fold_cols = 3,
handle_existing_fold_cols = "keep"
)
mixed_model_formulas <- c("Diagnosis ~ pitch_variability + (1|real_ID) + (1|Study)")
CV5 <- cross_validate(
data = fold_model_data,
formulas = mixed_model_formulas,
control = lme4::glmerControl(optimizer="bobyqa"),
fold_cols = paste0(".folds_", 1:3),
family = 'gaussian',
)
CV5 <- cross_validate(
data = fold_model_data,
formulas = mixed_model_formulas,
control = lme4::glmerControl(optimizer="bobyqa"),
fold_cols = paste0(".folds_", 1:3),
family = 'binomial',
)
fold_model_data <- danish_dat %>%
mutate(real_ID = as_factor(real_ID)) %>%
fold(
data = ., k = 10,
cat_col = 'diagnosis',
id_col = 'real_ID',
num_fold_cols = 3,
handle_existing_fold_cols = "keep"
)
mixed_model_formulas <- c("Diagnosis ~ pitch_variability + (1|real_ID) + (1|Study)")
CV5 <- cross_validate(
data = fold_model_data,
formulas = mixed_model_formulas,
control = lme4::glmerControl(optimizer="bobyqa"),
fold_cols = paste0(".folds_", 1:3),
family = 'binomial',
)
CV5 <- cross_validate(
data = fold_model_data,
formulas = model_formulas,
fold_cols = paste0(".folds_", 1:3),
family = 'binomial',
)
model_formulas <- c("Diagnosis ~ pitch_variability")
CV5 <- cross_validate(
data = fold_model_data,
formulas = model_formulas,
fold_cols = paste0(".folds_", 1:3),
family = 'binomial',
)
CV5
# Defining model
lr_mod <-
logistic_reg(penalty = 1,
mixture = 1) %>% # LASSO
set_engine("glmnet") %>%
set_mode("classification") %>%
fit(Diagnosis ~ ., new_data = danish_dat)
danish_dat
fold_model_data
fold_model_data %>% View()
fold_model_data
normalize <- function(x) {
(x-mean(x, na.rm = T)) / sd(x, na.rm = T)
}
fold_model_data <- danish_dat %>%
mutate(real_ID = as_factor(real_ID)) %>%
fold(
data = ., k = 10,
cat_col = 'diagnosis',
id_col = 'real_ID',
num_fold_cols = 3,
handle_existing_fold_cols = "keep"
) %>%
group_by(.folds_1) %>%
mutate(across(where(is.numeric), normalize))
fold_model_data <- danish_dat %>%
mutate(real_ID = as_factor(real_ID)) %>%
fold(
data = ., k = 10,
cat_col = 'diagnosis',
id_col = 'real_ID',
num_fold_cols = 3,
handle_existing_fold_cols = "keep"
) %>%
# normalizing within particion 1
group_by(.folds_1) %>%
mutate(across(where(is.numeric), normalize))
model_formulas <- c("Diagnosis ~ pitch_variability")
CV5 <- cross_validate(
data = fold_model_data,
formulas = model_formulas,
fold_cols = paste0(".folds_", 1:3),
family = 'binomial',
)
CV5
